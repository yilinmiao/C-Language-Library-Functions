{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMpRghepS5cFtXy+hazOEPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yilinmiao/C-Language-Library-Functions/blob/master/AI_Photo_Editing_with_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will build a nice web app that allows you to swap out the background of a subject and substitute it with an image generated by Stable Diffusion through a text prompt"
      ],
      "metadata": {
        "id": "rZdBGEQOR8yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Demo](https://youtu.be/f6mbaeb-I3w)"
      ],
      "metadata": {
        "id": "rD_N--JTMDWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpPoxQYgQawy"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import SamModel, SamProcessor\n",
        "from diffusers import DiffusionPipeline, AutoPipelineForText2Image, AutoPipelineForInpainting\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAM\n",
        "\n",
        "Complete the following cell by loading the pretrained SAM from Facebook/Meta. Remember to:\n",
        "\n",
        "1. Move the model to the GPU by adding `.to(\"cuda\")`\n",
        "2. Add the option `torch_dtype=torch.float16` to your call of AutoPipelineForInpainting.from_pretrained\n",
        "\n",
        "This cell might take a couple of minutes to load."
      ],
      "metadata": {
        "id": "_-tIbc2UTPrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SAM model as we have seen in the class\n",
        "# Remeber to load it on the GPU by adding .to(\"cuda\")\n",
        "# at the end\n",
        "model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(\"cuda\")\n",
        "\n",
        "# Load the SamProcessor using the facebook/sam-vit-base\n",
        "# checkpoint\n",
        "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
      ],
      "metadata": {
        "id": "gk-RfVwyTRmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the mask\n",
        "\n",
        "Now that you have loaded SAM, complete the following function that uses SAM to produce a segmentation mask:"
      ],
      "metadata": {
        "id": "evhD64qOTpKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_rgb(mask):\n",
        "    \"\"\"\n",
        "    Transforms a binary mask into an RGBA image for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    bg_transparent = np.zeros(mask.shape + (4, ), dtype=np.uint8)\n",
        "\n",
        "    # Color the area we will replace in green\n",
        "    # (this vector is [Red, Green, Blue, Alpha])\n",
        "    bg_transparent[mask == 1] = [0, 255, 0, 127]\n",
        "\n",
        "    return bg_transparent\n",
        "\n",
        "\n",
        "def get_processed_inputs(image, input_points):\n",
        "\n",
        "    # Use the processor to generate the right inputs\n",
        "    # for SAM\n",
        "    # Use \"image\" as your image\n",
        "    # Use 'input_points' as your input_points,\n",
        "    # and remember to use the option return_tensors='pt'\n",
        "    # Also, remember to add .to(\"cuda\") at the end\n",
        "    inputs = processor(\n",
        "        image,\n",
        "        input_points=input_points,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Call SAM\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Now let's post process the outputs of SAM to obtain the masks\n",
        "    masks = processor.image_processor.post_process_masks(\n",
        "       outputs.pred_masks.cpu(),\n",
        "       inputs[\"original_sizes\"].cpu(),\n",
        "       inputs[\"reshaped_input_sizes\"].cpu()\n",
        "    )\n",
        "\n",
        "    # Here we select the mask with the highest score\n",
        "    # as the mask we will use. You can experiment with also\n",
        "    # other selection criteria, for example the largest mask\n",
        "    # instead of the most confident mask\n",
        "    best_mask = masks[0][0][outputs.iou_scores.argmax()]\n",
        "\n",
        "    # NOTE: we invert the mask by using the ~ operator because\n",
        "    # so that the subject pixels will have a value of 0 and the\n",
        "    # background pixels a value of 1. This will make it more convenient\n",
        "    # to infill the background\n",
        "    return ~best_mask.cpu().numpy()"
      ],
      "metadata": {
        "id": "a-42v7GyTrJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's test what we have done so far. By executing this cell you should get a visualization of the mask for the following car.\n",
        "\n",
        "Let's see what happens in this cell:\n",
        "1. We open the image of the car and **we resize it to 512 by 512 pixels** (a square image). This makes things simpler for this project\n",
        "2. We define a few points on the image that indicate where the car is\n",
        "3. We use the function we have defined to generate a mask using SAM\n",
        "4. We visualize the mask"
      ],
      "metadata": {
        "id": "QWZwnZLQT28B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"car.png\").convert(\"RGB\").resize((512, 512))\n",
        "\n",
        "# These are the coordinates of two points on the car\n",
        "input_points = [[[150, 170], [300, 250]]]\n",
        "\n",
        "mask = get_processed_inputs(raw_image, input_points)\n",
        "\n",
        "Image.fromarray(mask_to_rgb(mask)).resize((128, 128))"
      ],
      "metadata": {
        "id": "hluDYknpT6N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inpainting\n",
        "\n",
        "Now that we have completed the SAM setup, let's move to the inpainting setup.\n",
        "\n",
        "Let's start by loading our inpainting pipeline. We will use the `diffusers/stable-diffusion-xl-1.0-inpainting-0.1` pretrained model and the `AutoPipelineForInpainting` as we have seen in our `diffusers` demo in Lesson 5.\n",
        "\n",
        "Complete the following code and run it (it might take a few minutes to run):\n",
        "\n",
        "> **NOTE**: you will probably see a warning similar to ``The config attributes {'decay'...``. Please ignore it. It is a warning generated by the diffusers library that does not constitute a problem for our application"
      ],
      "metadata": {
        "id": "XsTEDOe2T7Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the AutoPipelineForInpainting pipeline\n",
        "# The checkpoint we want to use is\n",
        "# \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\"\n",
        "# Remember to add torch_dtype=torch.float16 as an option\n",
        "\n",
        "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
        "    \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# This will make it more efficient on our hardware\n",
        "pipeline.enable_model_cpu_offload()\n",
        "# pipeline.scheduler.config.num_inference_steps = 25  # Default is 50"
      ],
      "metadata": {
        "id": "aHwNwn9ST8C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now complete the following function that gets in input:\n",
        "1. The raw image\n",
        "2. The mask generated by SAM (a numpy array)\n",
        "3. The text prompt for the infill\n",
        "4. An optional negative prompt\n",
        "5. An optional seed for repeatibility\n",
        "6. The Classifier-Free Guidance Scale (CFGS)."
      ],
      "metadata": {
        "id": "AswLVHePT9uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inpaint(raw_image, input_mask, prompt, negative_prompt=None, seed=74294536, cfgs=7):\n",
        "\n",
        "    mask_image = Image.fromarray(input_mask)\n",
        "\n",
        "    rand_gen = torch.manual_seed(seed)\n",
        "\n",
        "    # Use the pipeline we have created in the previous cell\n",
        "    # Use \"prompt\" as prompt,\n",
        "    # \"negative_prompt\" as the negative prompt,\n",
        "    # raw_image as the image,\n",
        "    # mask_image as the mask_image,\n",
        "    # rand_gen as the generator and\n",
        "    # cfgs as the guidance_scale\n",
        "\n",
        "    image = pipeline(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=raw_image,\n",
        "        mask_image=mask_image,\n",
        "        generator=rand_gen,\n",
        "        guidance_scale=cfgs\n",
        "    ).images[0]\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "abpoDdAPUAgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our inpainting on the mask we have obtained earlier with SAM:"
      ],
      "metadata": {
        "id": "qeRhHgDkUCk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a car driving on Mars. Studio lights, 1970s\"\n",
        "negative_prompt = \"artifacts, low quality, distortion\"\n",
        "\n",
        "image = inpaint(raw_image, mask, prompt, negative_prompt)"
      ],
      "metadata": {
        "id": "ecwMKQ9OUF6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at what we have produced:"
      ],
      "metadata": {
        "id": "K1XwgzsfUGnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_image_grid([raw_image, Image.fromarray(mask_to_rgb(mask)), image.resize((512, 512))], rows=1, cols=3)\n",
        "fig"
      ],
      "metadata": {
        "id": "THDJhFTVUIbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive app\n",
        "\n",
        "To make things a bit more fun, we have prepared an interactive app for you that uses the code you have completed and allow you to upload an image, run SAM, and generate the new background through a text prompt.\n",
        "\n",
        "Simply execute the following cell. The output will contain a preview of the app: **DO NOT USE IT**.\n",
        "\n",
        "Click on the second link (the public URL), from there you will be able to use the app much more comfortably.\n",
        "\n",
        "> NOTE: if for any reason you need to stop the app, click on the stop icon of the jupyter interface: then **execute the next cell containing the code `my_app.close`**\n"
      ],
      "metadata": {
        "id": "OjDVcNNvULeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "pxhJEwwenYuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import app"
      ],
      "metadata": {
        "id": "rLUJ5_QjUOER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_app = app.generate_app(get_processed_inputs, inpaint)"
      ],
      "metadata": {
        "id": "7bDAMq7gUO0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_app.close()"
      ],
      "metadata": {
        "id": "DsfOpi9EUP5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}